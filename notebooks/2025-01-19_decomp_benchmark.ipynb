{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TensorFactorization:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tensor, \n",
    "        rank, \n",
    "        method=\"cp\", \n",
    "        mask=None, \n",
    "        constraint=None,  \n",
    "        is_maximize_c=True,\n",
    "        device=None,\n",
    "        prev_state=None,   # Added for continual learning\n",
    "        verbose=False\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = device\n",
    "\n",
    "        # Move tensors to the device\n",
    "        tensor = tensor.to(self.device)\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(tensor, device=self.device)\n",
    "        else:\n",
    "            mask = mask.to(self.device)\n",
    "        if constraint is None:\n",
    "            constraint = torch.ones_like(tensor, device=self.device)\n",
    "        else:\n",
    "            constraint = constraint.to(self.device)\n",
    "\n",
    "        assert tensor.shape == mask.shape == constraint.shape, \\\n",
    "            \"Tensor, mask, and constraint must have the same shape.\"\n",
    "\n",
    "        self.tensor = tensor\n",
    "        self.mask = mask\n",
    "        self.constraint = constraint\n",
    "        self.is_maximize_c = is_maximize_c\n",
    "\n",
    "        self.method = method.lower()\n",
    "        self.total_params = 0  # Initialize total_params\n",
    "\n",
    "        if self.method == \"cp\":\n",
    "            self.rank = rank\n",
    "            self.dims = tensor.shape\n",
    "            # Initialize or create factor parameters\n",
    "            self.factors = [torch.randn(dim, rank, requires_grad=True, device=self.device) \n",
    "                            for dim in self.dims]\n",
    "            self.total_params = sum(factor.numel() for factor in self.factors)\n",
    "\n",
    "        elif self.method == \"tucker\":\n",
    "            self.rank = rank if isinstance(rank, tuple) else (rank,) * len(tensor.shape)\n",
    "            self.core = torch.randn(*self.rank, requires_grad=True, device=self.device)\n",
    "            self.factors = [torch.randn(dim, r, requires_grad=True, device=self.device) \n",
    "                            for dim, r in zip(tensor.shape, self.rank)]\n",
    "            self.total_params = self.core.numel() + sum(factor.numel() for factor in self.factors)\n",
    "\n",
    "        elif self.method == \"train\":\n",
    "            # Automatically expand rank to [1, rank, ..., rank, 1] if rank is int\n",
    "            if isinstance(rank, int):\n",
    "                rank = [1] + [rank] * (len(tensor.shape) - 1) + [1]\n",
    "\n",
    "            self.ranks = rank\n",
    "            assert self.ranks[0] == self.ranks[-1] == 1, \"Tensor Train ranks must start and end with 1.\"\n",
    "            assert len(self.ranks) == len(tensor.shape) + 1, \\\n",
    "                \"Ranks length must be equal to tensor dimensions + 1.\"\n",
    "            \n",
    "            self.factors = [\n",
    "                torch.randn(self.ranks[i], tensor.shape[i], self.ranks[i + 1], \n",
    "                            requires_grad=True, device=self.device)\n",
    "                for i in range(len(tensor.shape))\n",
    "            ]\n",
    "            self.total_params = sum(factor.numel() for factor in self.factors)\n",
    "\n",
    "\n",
    "        elif self.method == \"ring\":\n",
    "            self.rank = rank\n",
    "            self.factors = [\n",
    "                torch.randn(rank, tensor.shape[i], rank, requires_grad=True, device=self.device)\n",
    "                for i in range(len(tensor.shape))\n",
    "            ]\n",
    "            self.total_params = sum(factor.numel() for factor in self.factors)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}. Choose from 'cp', 'tucker', 'train', or 'ring'.\")\n",
    "\n",
    "        # Attempt to load previous state if provided\n",
    "        if prev_state is not None:\n",
    "            self._load_state(prev_state)\n",
    "            # print(\"Loaded from prev state!\")\n",
    "\n",
    "        # For logging\n",
    "        self.loss = None\n",
    "        self.mse_loss = None\n",
    "        self.constraint_loss = None\n",
    "        self.l2_loss = None\n",
    "        self.iter_end = None\n",
    "\n",
    "        self.loss_history = {\n",
    "            \"epoch\": [],\n",
    "            \"total\": [],\n",
    "            \"mse\": [],\n",
    "            \"constraint\": [],\n",
    "            \"l2\": [],\n",
    "        }\n",
    "\n",
    "        # Verbosity\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Initialized {method} decomposition with rank {rank} on device {self.device}.\")\n",
    "            logging.info(f\"Total parameters: {self.total_params}\")\n",
    "\n",
    "    def _load_state(self, prev_state):\n",
    "        \"\"\"\n",
    "        Simple demonstration of loading factor parameters from prev_state.\n",
    "        Modify according to how you save the states.\n",
    "        prev_state could be a list of Tensors or any structure you define.\n",
    "        \"\"\"\n",
    "        if self.method == \"cp\":\n",
    "            # Expecting prev_state to be a list of factor Tensors, same shape as self.factors\n",
    "            if len(prev_state) == len(self.factors):\n",
    "                for factor, saved_factor in zip(self.factors, prev_state):\n",
    "                    factor.data.copy_(saved_factor.data)\n",
    "        elif self.method == \"tucker\":\n",
    "            # Suppose prev_state = (core, [factor1, factor2, ...])\n",
    "            core, prev_factors = prev_state\n",
    "            self.core.data.copy_(core.data)\n",
    "            for f1, f2 in zip(self.factors, prev_factors):\n",
    "                f1.data.copy_(f2.data)\n",
    "        elif self.method == \"train\":\n",
    "            # Suppose prev_state is a list of TT-cores\n",
    "            for factor, saved_factor in zip(self.factors, prev_state):\n",
    "                factor.data.copy_(saved_factor.data)\n",
    "        elif self.method == \"ring\":\n",
    "            # Suppose prev_state is a list of ring factors\n",
    "            for factor, saved_factor in zip(self.factors, prev_state):\n",
    "                factor.data.copy_(saved_factor.data)\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Return the current factor parameters (and core if tucker, etc.).\n",
    "        This can be used for continual optimization in TFSampler.\n",
    "        \"\"\"\n",
    "        if self.method == \"cp\":\n",
    "            return [factor.clone().detach() for factor in self.factors]\n",
    "        elif self.method == \"tucker\":\n",
    "            return (\n",
    "                self.core.clone().detach(),\n",
    "                [factor.clone().detach() for factor in self.factors]\n",
    "            )\n",
    "        elif self.method == \"train\":\n",
    "            return [factor.clone().detach() for factor in self.factors]\n",
    "        elif self.method == \"ring\":\n",
    "            return [factor.clone().detach() for factor in self.factors]\n",
    "\n",
    "    def reconstruct(self):\n",
    "        \"\"\"\n",
    "        Reconstruct the tensor based on the decomposition method.\n",
    "        \"\"\"\n",
    "        if self.method == \"cp\":\n",
    "            R = self.rank\n",
    "            recon = torch.zeros_like(self.tensor, device=self.device)\n",
    "            for r in range(R):\n",
    "                # Outer product across all modes\n",
    "                component = self.factors[0][:, r]\n",
    "                for mode in range(1, len(self.dims)):\n",
    "                    component = torch.ger(component, self.factors[mode][:, r]).flatten()\n",
    "                # Reshape it back to self.dims\n",
    "                recon += component.view(*self.dims)\n",
    "            return recon\n",
    "\n",
    "        elif self.method == \"tucker\":\n",
    "            # Start with core\n",
    "            recon = self.core\n",
    "            # Repeatedly tensordot with factor matrices\n",
    "            for i, factor in enumerate(self.factors):\n",
    "                recon = torch.tensordot(recon, factor, dims=[[0], [1]])\n",
    "            return recon\n",
    "\n",
    "        elif self.method == \"train\":\n",
    "            # TT decomposition reconstruction with einsum\n",
    "            recon = self.factors[0]\n",
    "            for factor in self.factors[1:]:\n",
    "                recon = torch.einsum(\"...i,ijk->...jk\", recon, factor)\n",
    "            return recon.squeeze()\n",
    "\n",
    "        elif self.method == \"ring\":\n",
    "            # Very rough ring decomposition reconstruction\n",
    "            n_modes = len(self.factors)\n",
    "            result = self.factors[0]\n",
    "            for i in range(1, n_modes - 1):\n",
    "                result = torch.einsum('ijk,klm->ijlm', result, self.factors[i])\n",
    "                s1, s2, s3, s4 = result.shape\n",
    "                result = result.reshape(s1, s2 * s3, s4)\n",
    "            result = torch.einsum('ijk,klm->jl', result, self.factors[-1])\n",
    "            result = result.reshape(self.tensor.shape)\n",
    "            return result\n",
    "\n",
    "    def optimize(\n",
    "        self, \n",
    "        lr=0.01, \n",
    "        max_iter=None, \n",
    "        tol=1e-6, \n",
    "        mse_tol=1e-1, \n",
    "        const_tol=1e-1, \n",
    "        reg_lambda=0.0, \n",
    "        constraint_lambda=1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform optimization for the specified decomposition method.\n",
    "\n",
    "        Args:\n",
    "          - lr: float, learning rate\n",
    "          - max_iter: int or None, maximum number of iterations (if None, stop based on tol)\n",
    "          - tol: float, tolerance for total loss change\n",
    "          - mse_tol: float, tolerance for MSE loss\n",
    "          - const_tol: float, tolerance for constraint loss\n",
    "          - reg_lambda: float, L2 regularization coefficient\n",
    "          - constraint_lambda: float, penalty coefficient for constraint violations\n",
    "\n",
    "        Returns:\n",
    "          - factors: (Optional) Possibly return the updated factors for reuse\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        if self.method == \"tucker\":\n",
    "            params = [self.core] + self.factors\n",
    "        else:\n",
    "            params = self.factors\n",
    "\n",
    "        optimizer = optim.Adam(params, lr=lr)\n",
    "        # optimizer = optim.Adam(params, lr=lr, weight_decay=0.01)\n",
    "        # optimizer = optim.SGD(params, lr=lr)\n",
    "        # optimizer = optim.SGD(params, lr=lr, momentum=0.01)\n",
    "        prev_loss = float('inf')\n",
    "        iteration = 0\n",
    "\n",
    "        min_iter = 10\n",
    "\n",
    "        while True:\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction = self.reconstruct()\n",
    "\n",
    "            def loss_fn():\n",
    "                # Count of observed entries\n",
    "                n_se = torch.sum(self.mask)\n",
    "                # Count of constraint-violating entries\n",
    "                n_c = torch.sum(1 - self.constraint)\n",
    "                n_c = n_c if n_c > 0 else 1\n",
    "                \n",
    "                error_term = self.constraint * self.mask * (self.tensor - reconstruction)\n",
    "                mse_loss = torch.norm(error_term) ** 2 / n_se if n_se > 0 else 0\n",
    "\n",
    "                if self.is_maximize_c:\n",
    "                    sign = 1\n",
    "                    thr = torch.min(self.tensor)\n",
    "                else:\n",
    "                    sign = -1\n",
    "                    thr = torch.max(self.tensor)\n",
    "\n",
    "                violation_term = torch.clamp(\n",
    "                    (1 - self.constraint) * sign * (reconstruction - thr),\n",
    "                    min=0\n",
    "                )\n",
    "                constraint_loss = constraint_lambda * torch.sum(violation_term) / n_c\n",
    "\n",
    "                # L2 regularization\n",
    "                l2_loss = torch.tensor(0., device=self.device, dtype=mse_loss.dtype)\n",
    "                for p in params:\n",
    "                    l2_loss += torch.norm(p) ** 2 / p.numel()\n",
    "                l2_loss *= reg_lambda\n",
    "\n",
    "                total_loss = mse_loss + constraint_loss + l2_loss\n",
    "                return total_loss, mse_loss, constraint_loss, l2_loss\n",
    "\n",
    "            loss, mse_loss, c_loss, l2_loss = loss_fn()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            self.loss = loss\n",
    "            self.mse_loss = mse_loss\n",
    "            self.constraint_loss = c_loss\n",
    "            self.l2_loss = l2_loss\n",
    "\n",
    "            self.loss_history[\"epoch\"].append(iteration+1)\n",
    "            self.loss_history[\"total\"].append(loss.item())\n",
    "            self.loss_history[\"mse\"].append(mse_loss.item())\n",
    "            self.loss_history[\"constraint\"].append(c_loss.item())\n",
    "            self.loss_history[\"l2\"].append(l2_loss.item())\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Iter: {iteration}, Loss: {loss.item()}\")\n",
    "                logging.info(f\"MSE: {mse_loss.item()}, CONST: {c_loss.item()}, L2: {l2_loss.item()}\")\n",
    "\n",
    "            # Check for MSE and constraint convergence\n",
    "            if mse_loss < mse_tol and c_loss < const_tol and iteration > min_iter:\n",
    "                if self.verbose:\n",
    "                    logging.info(\"Converged based on MSE and constraint tolerance.\")\n",
    "                break\n",
    "\n",
    "            # Check for total loss difference\n",
    "            if abs(prev_loss - loss.item()) < tol and iteration > min_iter:\n",
    "                if self.verbose:\n",
    "                    logging.info(\"Converged based on total loss tolerance.\")\n",
    "                break\n",
    "\n",
    "            if max_iter is not None and iteration >= max_iter - 1 and iteration > min_iter:\n",
    "                if self.verbose:\n",
    "                    logging.info(\"Reached max iteration limit.\")\n",
    "                break\n",
    "\n",
    "            prev_loss = loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        self.iter_end = iteration\n",
    "\n",
    "        return [p.detach() for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def benchmarking(\n",
    "    shape,\n",
    "    rank=3,\n",
    "    method=\"train\"\n",
    "):\n",
    "    accuracy = []\n",
    "    time_taken = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        # 元テンソル\n",
    "        original_tensor = torch.randn(shape)   \n",
    "\n",
    "        # テンソル分解\n",
    "        rank = 3\n",
    "        method = \"train\"\n",
    "\n",
    "        decomp = TensorFactorization(\n",
    "            tensor=original_tensor, \n",
    "            rank=rank, \n",
    "            method=method\n",
    "        )\n",
    "\n",
    "        s = time()\n",
    "        decomp.optimize()\n",
    "        e = time()\n",
    "        # print(f\"Time: {e-s}\")\n",
    "\n",
    "        reconstructed_tensor = decomp.reconstruct()\n",
    "        mse = torch.mean((original_tensor - reconstructed_tensor) ** 2)\n",
    "        # print(f\"MSE: {mse}\")\n",
    "\n",
    "        accuracy.append(mse.item())\n",
    "        time_taken.append(e-s)\n",
    "\n",
    "    return accuracy, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Accuracy: 0.998685771226883\n",
      "Time taken: 5.486046981811524\n",
      "\n",
      "Rank: 3\n",
      "Accuracy: 0.9982442557811737\n",
      "Time taken: 6.0472664594650265\n",
      "\n",
      "Rank: 4\n",
      "Accuracy: 1.0008959352970124\n",
      "Time taken: 7.091440510749817\n",
      "\n",
      "Rank: 5\n",
      "Accuracy: 1.000096708536148\n",
      "Time taken: 5.578088855743408\n",
      "\n",
      "Rank: 6\n",
      "Accuracy: 1.0009174346923828\n",
      "Time taken: 6.026907014846802\n",
      "\n",
      "Rank: 7\n",
      "Accuracy: 0.9991318643093109\n",
      "Time taken: 7.623436284065247\n",
      "\n",
      "Rank: 8\n",
      "Accuracy: 0.9985550880432129\n",
      "Time taken: 6.29259238243103\n",
      "\n",
      "Rank: 9\n",
      "Accuracy: 0.9991213262081147\n",
      "Time taken: 5.931344485282898\n",
      "\n",
      "Rank: 10\n",
      "Accuracy: 1.000857025384903\n",
      "Time taken: 6.459856557846069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"train\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Accuracy: 1.0015193164348601\n",
      "Time taken: 6.328765225410462\n",
      "\n",
      "Rank: 3\n",
      "Accuracy: 1.0028085827827453\n",
      "Time taken: 7.8232728242874146\n",
      "\n",
      "Rank: 4\n",
      "Accuracy: 0.9991190433502197\n",
      "Time taken: 6.5175905466079715\n",
      "\n",
      "Rank: 5\n",
      "Accuracy: 0.9983286440372467\n",
      "Time taken: 6.043672394752503\n",
      "\n",
      "Rank: 6\n",
      "Accuracy: 1.0012374877929688\n",
      "Time taken: 6.21276969909668\n",
      "\n",
      "Rank: 7\n",
      "Accuracy: 0.9987181007862092\n",
      "Time taken: 7.223810911178589\n",
      "\n",
      "Rank: 8\n",
      "Accuracy: 0.9992061495780945\n",
      "Time taken: 7.778573894500733\n",
      "\n",
      "Rank: 9\n",
      "Accuracy: 1.0012026131153107\n",
      "Time taken: 7.613510584831237\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m rank_list:\n\u001b[0;32m----> 8\u001b[0m     accuracy, time_taken \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmarking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mring\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(accuracy)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m, in \u001b[0;36mbenchmarking\u001b[0;34m(shape, rank, method)\u001b[0m\n\u001b[1;32m     21\u001b[0m decomp \u001b[38;5;241m=\u001b[39m TensorFactorization(\n\u001b[1;32m     22\u001b[0m     tensor\u001b[38;5;241m=\u001b[39moriginal_tensor, \n\u001b[1;32m     23\u001b[0m     rank\u001b[38;5;241m=\u001b[39mrank, \n\u001b[1;32m     24\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m s \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mdecomp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m e \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(f\"Time: {e-s}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 278\u001b[0m, in \u001b[0;36mTensorFactorization.optimize\u001b[0;34m(self, lr, max_iter, tol, mse_tol, const_tol, reg_lambda, constraint_lambda)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, mse_loss, constraint_loss, l2_loss\n\u001b[1;32m    277\u001b[0m loss, mse_loss, c_loss, l2_loss \u001b[38;5;241m=\u001b[39m loss_fn()\n\u001b[0;32m--> 278\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"ring\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=\"ring\"\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"cp\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=\"ring\"\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def benchmarking(\n",
    "    shape,\n",
    "    rank=3,\n",
    "    method=\"train\"\n",
    "):\n",
    "    accuracy = []\n",
    "    time_taken = []\n",
    "    step_taken = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        # 元テンソル\n",
    "        original_tensor = torch.randn(shape)   \n",
    "\n",
    "        # テンソル分解\n",
    "        rank = 3\n",
    "        method = \"train\"\n",
    "\n",
    "        decomp = TensorFactorization(\n",
    "            tensor=original_tensor, \n",
    "            rank=rank, \n",
    "            method=method\n",
    "        )\n",
    "\n",
    "        s = time()\n",
    "        decomp.optimize()\n",
    "        e = time()\n",
    "        # print(f\"Time: {e-s}\")\n",
    "\n",
    "        reconstructed_tensor = decomp.reconstruct()\n",
    "        mse = torch.mean((original_tensor - reconstructed_tensor) ** 2)\n",
    "        # print(f\"MSE: {mse}\")\n",
    "\n",
    "        accuracy.append(mse.item())\n",
    "        time_taken.append(e-s)\n",
    "        step_taken.append(decomp.loss_history[\"epoch\"][-1])\n",
    "\n",
    "    return accuracy, time_taken, step_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Accuracy: 1.0020390748977661\n",
      "Time taken: 6.7535542249679565\n",
      "Step taken: 2343.8\n",
      "\n",
      "Rank: 3\n",
      "Accuracy: 1.0002936720848083\n",
      "Time taken: 7.102569842338562\n",
      "Step taken: 2514.6\n",
      "\n",
      "Rank: 4\n",
      "Accuracy: 1.0009375631809234\n",
      "Time taken: 7.201712512969971\n",
      "Step taken: 2302.7\n",
      "\n",
      "Rank: 5\n",
      "Accuracy: 1.000908410549164\n",
      "Time taken: 7.112463784217835\n",
      "Step taken: 2621.6\n",
      "\n",
      "Rank: 6\n",
      "Accuracy: 1.004307508468628\n",
      "Time taken: 6.628024053573609\n",
      "Step taken: 2510.3\n",
      "\n",
      "Rank: 7\n",
      "Accuracy: 1.0007879614830018\n",
      "Time taken: 6.007804942131043\n",
      "Step taken: 2191.3\n",
      "\n",
      "Rank: 8\n",
      "Accuracy: 1.0001854240894317\n",
      "Time taken: 6.704331183433533\n",
      "Step taken: 2403.2\n",
      "\n",
      "Rank: 9\n",
      "Accuracy: 1.0000901699066163\n",
      "Time taken: 6.372687268257141\n",
      "Step taken: 2423.8\n",
      "\n",
      "Rank: 10\n",
      "Accuracy: 0.9984685897827148\n",
      "Time taken: 7.606977391242981\n",
      "Step taken: 2714.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"train\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Accuracy: 0.9987840533256531\n",
      "Time taken: 7.539689731597901\n",
      "Step taken: 2575.2\n",
      "\n",
      "Rank: 3\n",
      "Accuracy: 1.0015023589134215\n",
      "Time taken: 8.104411673545837\n",
      "Step taken: 2898.8\n",
      "\n",
      "Rank: 4\n",
      "Accuracy: 1.000743991136551\n",
      "Time taken: 6.626764225959778\n",
      "Step taken: 2535.0\n",
      "\n",
      "Rank: 5\n",
      "Accuracy: 0.9986528515815735\n",
      "Time taken: 7.0723450660705565\n",
      "Step taken: 2670.5\n",
      "\n",
      "Rank: 6\n",
      "Accuracy: 1.0023885428905488\n",
      "Time taken: 6.656932139396668\n",
      "Step taken: 2519.3\n",
      "\n",
      "Rank: 7\n",
      "Accuracy: 1.000109899044037\n",
      "Time taken: 6.311275243759155\n",
      "Step taken: 2376.7\n",
      "\n",
      "Rank: 8\n",
      "Accuracy: 0.9974024713039398\n",
      "Time taken: 6.328418850898743\n",
      "Step taken: 2371.4\n",
      "\n",
      "Rank: 9\n",
      "Accuracy: 0.9978284299373626\n",
      "Time taken: 7.016313552856445\n",
      "Step taken: 2661.0\n",
      "\n",
      "Rank: 10\n",
      "Accuracy: 1.000124216079712\n",
      "Time taken: 6.521069741249084\n",
      "Step taken: 2475.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"ring\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "Accuracy: 1.0019038379192353\n",
      "Time taken: 6.192322373390198\n",
      "Step taken: 2169.6\n",
      "\n",
      "Rank: 3\n",
      "Accuracy: 1.00194793343544\n",
      "Time taken: 7.4224138259887695\n",
      "Step taken: 2724.9\n",
      "\n",
      "Rank: 4\n",
      "Accuracy: 1.0003471314907073\n",
      "Time taken: 6.919440889358521\n",
      "Step taken: 2505.5\n",
      "\n",
      "Rank: 5\n",
      "Accuracy: 1.0014607787132264\n",
      "Time taken: 6.8373579502105715\n",
      "Step taken: 2536.5\n",
      "\n",
      "Rank: 6\n",
      "Accuracy: 0.9976076781749725\n",
      "Time taken: 8.152693128585815\n",
      "Step taken: 2321.6\n",
      "\n",
      "Rank: 7\n",
      "Accuracy: 1.0016708433628083\n",
      "Time taken: 7.26188292503357\n",
      "Step taken: 2415.7\n",
      "\n",
      "Rank: 8\n",
      "Accuracy: 1.00036159157753\n",
      "Time taken: 5.317220759391785\n",
      "Step taken: 1971.3\n",
      "\n",
      "Rank: 9\n",
      "Accuracy: 1.0005896508693695\n",
      "Time taken: 6.72185447216034\n",
      "Step taken: 2394.5\n",
      "\n",
      "Rank: 10\n",
      "Accuracy: 1.0012098729610444\n",
      "Time taken: 7.401428127288819\n",
      "Step taken: 2530.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "method = \"cp\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 10\n",
      "Accuracy: 0.9998419880867004\n",
      "Time taken: 6.392620706558228\n",
      "Step taken: 2421.4\n",
      "\n",
      "Rank: 20\n",
      "Accuracy: 1.000387966632843\n",
      "Time taken: 5.656297183036804\n",
      "Step taken: 2117.5\n",
      "\n",
      "Rank: 30\n",
      "Accuracy: 0.9990622818470001\n",
      "Time taken: 7.381319355964661\n",
      "Step taken: 2773.5\n",
      "\n",
      "Rank: 40\n",
      "Accuracy: 0.9994167149066925\n",
      "Time taken: 5.943284726142883\n",
      "Step taken: 2196.2\n",
      "\n",
      "Rank: 50\n",
      "Accuracy: 1.000184828042984\n",
      "Time taken: 6.265983366966248\n",
      "Step taken: 2231.8\n",
      "\n",
      "Rank: 60\n",
      "Accuracy: 0.9982640624046326\n",
      "Time taken: 6.768451595306397\n",
      "Step taken: 2328.4\n",
      "\n",
      "Rank: 70\n",
      "Accuracy: 0.998406320810318\n",
      "Time taken: 7.097509336471558\n",
      "Step taken: 2437.0\n",
      "\n",
      "Rank: 80\n",
      "Accuracy: 1.0008914411067962\n",
      "Time taken: 6.898731017112732\n",
      "Step taken: 2423.4\n",
      "\n",
      "Rank: 90\n",
      "Accuracy: 1.000275868177414\n",
      "Time taken: 7.612854647636413\n",
      "Step taken: 2911.2\n",
      "\n",
      "Rank: 100\n",
      "Accuracy: 0.9982196629047394\n",
      "Time taken: 6.03432605266571\n",
      "Step taken: 2424.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "method = \"train\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 10\n",
      "Accuracy: 1.0001344203948974\n",
      "Time taken: 6.37033360004425\n",
      "Step taken: 2561.7\n",
      "\n",
      "Rank: 20\n",
      "Accuracy: 1.0027559459209443\n",
      "Time taken: 5.56131808757782\n",
      "Step taken: 2232.0\n",
      "\n",
      "Rank: 30\n",
      "Accuracy: 0.9990893423557281\n",
      "Time taken: 6.2405870199203495\n",
      "Step taken: 2537.8\n",
      "\n",
      "Rank: 40\n",
      "Accuracy: 0.9998206496238708\n",
      "Time taken: 5.925774693489075\n",
      "Step taken: 2366.2\n",
      "\n",
      "Rank: 50\n",
      "Accuracy: 0.9981076419353485\n",
      "Time taken: 5.402565693855285\n",
      "Step taken: 2170.9\n",
      "\n",
      "Rank: 60\n",
      "Accuracy: 1.001162850856781\n",
      "Time taken: 5.616523742675781\n",
      "Step taken: 2305.2\n",
      "\n",
      "Rank: 70\n",
      "Accuracy: 0.9991840958595276\n",
      "Time taken: 5.926495456695557\n",
      "Step taken: 2376.9\n",
      "\n",
      "Rank: 80\n",
      "Accuracy: 0.9990240037441254\n",
      "Time taken: 5.999073195457458\n",
      "Step taken: 2410.2\n",
      "\n",
      "Rank: 90\n",
      "Accuracy: 0.999521940946579\n",
      "Time taken: 7.303771543502807\n",
      "Step taken: 2934.8\n",
      "\n",
      "Rank: 100\n",
      "Accuracy: 0.9983904242515564\n",
      "Time taken: 5.676851296424866\n",
      "Step taken: 2265.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "method = \"ring\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 10\n",
      "Accuracy: 0.9997683227062225\n",
      "Time taken: 6.618064308166504\n",
      "Step taken: 2647.3\n",
      "\n",
      "Rank: 20\n",
      "Accuracy: 1.0010520696640015\n",
      "Time taken: 7.25626494884491\n",
      "Step taken: 2911.6\n",
      "\n",
      "Rank: 30\n",
      "Accuracy: 0.9988561868667603\n",
      "Time taken: 6.383202576637268\n",
      "Step taken: 2555.8\n",
      "\n",
      "Rank: 40\n",
      "Accuracy: 1.0018435418605804\n",
      "Time taken: 5.53312463760376\n",
      "Step taken: 2232.0\n",
      "\n",
      "Rank: 50\n",
      "Accuracy: 1.0001993834972382\n",
      "Time taken: 5.640861392021179\n",
      "Step taken: 2237.2\n",
      "\n",
      "Rank: 60\n",
      "Accuracy: 1.0012370705604554\n",
      "Time taken: 5.654657244682312\n",
      "Step taken: 2256.7\n",
      "\n",
      "Rank: 70\n",
      "Accuracy: 1.001906579732895\n",
      "Time taken: 5.949770569801331\n",
      "Step taken: 2364.3\n",
      "\n",
      "Rank: 80\n",
      "Accuracy: 1.0022528767585754\n",
      "Time taken: 5.410847902297974\n",
      "Step taken: 2154.1\n",
      "\n",
      "Rank: 90\n",
      "Accuracy: 1.000049215555191\n",
      "Time taken: 5.961901760101318\n",
      "Step taken: 2349.9\n",
      "\n",
      "Rank: 100\n",
      "Accuracy: 1.0018891990184784\n",
      "Time taken: 5.722808074951172\n",
      "Step taken: 2252.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "shape = (7,) * 6\n",
    "\n",
    "rank_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "method = \"cp\"\n",
    "\n",
    "for rank in rank_list:\n",
    "    accuracy, time_taken, step_taken = benchmarking(\n",
    "        shape,\n",
    "        rank=rank,\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "    print(f\"Rank: {rank}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Time taken: {np.mean(time_taken)}\")\n",
    "    print(f\"Step taken: {np.mean(step_taken)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-env_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
